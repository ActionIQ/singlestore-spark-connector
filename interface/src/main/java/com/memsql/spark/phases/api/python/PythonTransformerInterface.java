package com.memsql.spark.phases.api.python;

import java.io.Serializable;

import org.apache.spark.sql.SQLContext;
import org.apache.spark.sql.DataFrame;

import com.memsql.spark.etl.api.PhaseConfig;
import com.memsql.spark.etl.utils.PhaseLogger;

/**
 * Python Pipeline Transformer interface.
 * This interface is implemented by Transformers in Python via Py4J.
 */
public interface PythonTransformerInterface extends Serializable {
    /**
     * Initialization code for this Transformer
     *
     * @param sqlContext The SQLContext that is used to run this pipeline.
     *                   NOTE: If the pipeline is running in MemSQL Streamliner, this is an instance of
     *                   [[com.memsql.spark.context.MemSQLContext]], which has additional metadata about the MemSQL cluster.
     * @param logger A logger instance that is integrated with MemSQL Ops.
     */
    void Py4JInitialize(SQLContext sqlContext, PhaseLogger logger);

    /**
     * Cleanup code for this Transformer
     *
     * @param sqlContext The SQLContext that is used to run this pipeline.
     *                   NOTE: If the pipeline is running in MemSQL Streamliner, this is an instance of
     *                   [[com.memsql.spark.context.MemSQLContext]], which has additional metadata about the MemSQL cluster.
     * @param logger A logger instance that is integrated with MemSQL Ops.
     */
    void Py4JCleanup(SQLContext sqlContext, PhaseLogger logger);

    /**
     * Transforms the incoming [[org.apache.spark.sql.DataFrame]].
     *
     * @param sqlContext The SQLContext that is used to run this pipeline.
     *                   NOTE: If the pipeline is running in MemSQL Streamliner, this is an instance of
     *                   [[com.memsql.spark.context.MemSQLContext]], which has additional metadata about the MemSQL cluster.
     * @param df The [[org.apache.spark.sql.DataFrame]] generated by the Transformer for this batch.
     * @param logger A logger instance that is integrated with MemSQL Ops.
     * @return A [[org.apache.spark.sql.DataFrame]] with the transformed data to be loaded.
     */
    DataFrame Py4JTransform(SQLContext sqlContext, DataFrame df, PhaseLogger logger);
}
